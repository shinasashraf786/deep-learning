{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0786a9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 14:10:53.281939: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac226363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample text data\n",
    "texts = [\n",
    "    \"This is the first document. \",\n",
    "    \"This document is the second document. \",\n",
    "    \"And this is the third one. \",\n",
    "    \"Is this the first document?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c95d326",
   "metadata": {},
   "source": [
    "Tokenize the text: Split your text into Individual words or tokens.\n",
    "Create a vocabulary: Build a vocabulary mapping each unique word/token to an integer index.\n",
    "Convert text to sequences: Replace each word/token in the text with its corresponding integer index based on the vocabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ea956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1: Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_index=tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daa5224a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 1,\n",
       " 'is': 2,\n",
       " 'the': 3,\n",
       " 'document': 4,\n",
       " 'first': 5,\n",
       " 'second': 6,\n",
       " 'and': 7,\n",
       " 'third': 8,\n",
       " 'one': 9}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9802396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2:Convert text to sequences\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b45c7dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 5, 4], [1, 4, 2, 3, 6, 4], [7, 1, 2, 3, 8, 9], [2, 1, 3, 5, 4]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812c8a19",
   "metadata": {},
   "source": [
    "tokenize the text using Tokenizer and convert it into sequences of integers, pad the sequences to ensure they all have the same length.\n",
    "then create an embedding matrix using Embedding layer, where each word index in the sequences is mapped to a dense vector representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d39da92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step3: pad sequences(optional)\n",
    "#Ensure all sequences have the same length by padding them with zeros or truncating them.\n",
    "\n",
    "max_sequence_length = max([len(seq) for seq in sequences])\n",
    "\n",
    "sequences_padded = pad_sequences(sequences, max_sequence_length,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b90cf8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 5, 4, 0],\n",
       "       [1, 4, 2, 3, 6, 4],\n",
       "       [7, 1, 2, 3, 8, 9],\n",
       "       [2, 1, 3, 5, 4, 0]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e360ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4: Apply Embeddeding layer\n",
    "vocab_size = len(word_index) + 1 #Add 1 for the padding token\n",
    "embedding_dim = 10 #Dimensionality of the dense embedding\n",
    "embedding_matrix = tf.keras.layers.Embedding(vocab_size,embedding_dim)(sequences_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57fe22c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b4087d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6, 10), dtype=float32, numpy=\n",
       "array([[[-0.02462852, -0.03239276, -0.01633903, -0.02879429,\n",
       "         -0.00597594,  0.00267736,  0.03933405, -0.00447339,\n",
       "          0.01258976, -0.00805227],\n",
       "        [ 0.01320871,  0.04057591,  0.04310811, -0.02795578,\n",
       "          0.03285135, -0.0220477 , -0.0276749 ,  0.00879598,\n",
       "         -0.01257243, -0.00731296],\n",
       "        [-0.00112033, -0.0274989 , -0.01941402,  0.03740039,\n",
       "          0.02167271,  0.043897  , -0.01676438,  0.03806067,\n",
       "         -0.04262164,  0.01647612],\n",
       "        [ 0.01266922, -0.02711682, -0.01906847, -0.02273291,\n",
       "          0.02866424, -0.00551039,  0.01910396,  0.02294696,\n",
       "          0.04056872,  0.04903822],\n",
       "        [ 0.01748944, -0.0207118 , -0.0221781 ,  0.02035685,\n",
       "         -0.04420285, -0.02716148,  0.03583176,  0.03661368,\n",
       "         -0.00591414,  0.02284663],\n",
       "        [ 0.00608613, -0.04886366, -0.02538626,  0.03250617,\n",
       "          0.03394547,  0.02606091, -0.02088164, -0.0145107 ,\n",
       "          0.01942391, -0.03785391]],\n",
       "\n",
       "       [[-0.02462852, -0.03239276, -0.01633903, -0.02879429,\n",
       "         -0.00597594,  0.00267736,  0.03933405, -0.00447339,\n",
       "          0.01258976, -0.00805227],\n",
       "        [ 0.01748944, -0.0207118 , -0.0221781 ,  0.02035685,\n",
       "         -0.04420285, -0.02716148,  0.03583176,  0.03661368,\n",
       "         -0.00591414,  0.02284663],\n",
       "        [ 0.01320871,  0.04057591,  0.04310811, -0.02795578,\n",
       "          0.03285135, -0.0220477 , -0.0276749 ,  0.00879598,\n",
       "         -0.01257243, -0.00731296],\n",
       "        [-0.00112033, -0.0274989 , -0.01941402,  0.03740039,\n",
       "          0.02167271,  0.043897  , -0.01676438,  0.03806067,\n",
       "         -0.04262164,  0.01647612],\n",
       "        [ 0.00640892, -0.03681713, -0.0432492 ,  0.00620476,\n",
       "         -0.04295136, -0.01662263,  0.01953078, -0.01684172,\n",
       "          0.01541085, -0.01088803],\n",
       "        [ 0.01748944, -0.0207118 , -0.0221781 ,  0.02035685,\n",
       "         -0.04420285, -0.02716148,  0.03583176,  0.03661368,\n",
       "         -0.00591414,  0.02284663]],\n",
       "\n",
       "       [[ 0.03159324, -0.02134297, -0.0205593 , -0.0143517 ,\n",
       "          0.04202378, -0.04625533,  0.0221386 , -0.00210874,\n",
       "          0.00171668, -0.02590472],\n",
       "        [-0.02462852, -0.03239276, -0.01633903, -0.02879429,\n",
       "         -0.00597594,  0.00267736,  0.03933405, -0.00447339,\n",
       "          0.01258976, -0.00805227],\n",
       "        [ 0.01320871,  0.04057591,  0.04310811, -0.02795578,\n",
       "          0.03285135, -0.0220477 , -0.0276749 ,  0.00879598,\n",
       "         -0.01257243, -0.00731296],\n",
       "        [-0.00112033, -0.0274989 , -0.01941402,  0.03740039,\n",
       "          0.02167271,  0.043897  , -0.01676438,  0.03806067,\n",
       "         -0.04262164,  0.01647612],\n",
       "        [-0.00710662, -0.00402157,  0.04213065,  0.01649361,\n",
       "          0.0449467 , -0.0292671 ,  0.00620327,  0.00236263,\n",
       "         -0.04931618,  0.02974774],\n",
       "        [ 0.01042854, -0.02951937, -0.0011548 ,  0.04875124,\n",
       "          0.03809052, -0.04686879, -0.00864176, -0.01865679,\n",
       "          0.01867275, -0.0442192 ]],\n",
       "\n",
       "       [[ 0.01320871,  0.04057591,  0.04310811, -0.02795578,\n",
       "          0.03285135, -0.0220477 , -0.0276749 ,  0.00879598,\n",
       "         -0.01257243, -0.00731296],\n",
       "        [-0.02462852, -0.03239276, -0.01633903, -0.02879429,\n",
       "         -0.00597594,  0.00267736,  0.03933405, -0.00447339,\n",
       "          0.01258976, -0.00805227],\n",
       "        [-0.00112033, -0.0274989 , -0.01941402,  0.03740039,\n",
       "          0.02167271,  0.043897  , -0.01676438,  0.03806067,\n",
       "         -0.04262164,  0.01647612],\n",
       "        [ 0.01266922, -0.02711682, -0.01906847, -0.02273291,\n",
       "          0.02866424, -0.00551039,  0.01910396,  0.02294696,\n",
       "          0.04056872,  0.04903822],\n",
       "        [ 0.01748944, -0.0207118 , -0.0221781 ,  0.02035685,\n",
       "         -0.04420285, -0.02716148,  0.03583176,  0.03661368,\n",
       "         -0.00591414,  0.02284663],\n",
       "        [ 0.00608613, -0.04886366, -0.02538626,  0.03250617,\n",
       "          0.03394547,  0.02606091, -0.02088164, -0.0145107 ,\n",
       "          0.01942391, -0.03785391]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "765acea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 10)\n"
     ]
    }
   ],
   "source": [
    "#print the embedding matrix shape\n",
    "print(embedding_matrix.shape)  #Output: (num_samples , max_sequence_length,embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44066091",
   "metadata": {},
   "source": [
    "Dimension 1 (4): This dimension corresponds to the number of samples in your input data. In this case, you have 4 samples (or sentences/documents).\n",
    "Dimension 2 (6): This dimension represents the length of the sequences after padding. Since you've padded the sequences to a length of 6, this dimension is\n",
    "Dimension 3 (100): This dimension is the dimensionality of the dense embedding vectors. You've chosen an embedding dimension of 100, so each word is represented by a dense vector of length 100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f91caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
